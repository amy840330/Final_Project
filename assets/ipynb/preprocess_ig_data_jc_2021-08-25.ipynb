{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba58ca61",
   "metadata": {},
   "source": [
    "# Text Preprocessing in Natural Language Processing\n",
    "Tokenize Text Columns Into Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174afabd",
   "metadata": {},
   "source": [
    "Required libraries\n",
    "<br>\n",
    "[pip install spacy](https://pypi.org/project/spacy/)\n",
    "<br>\n",
    "Input the following into gitbash: \"python -m spacy download en_core_web_sm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41fd2834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies and setup\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fe4f647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>author</th>\n",
       "      <th>shortcode</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>caption</th>\n",
       "      <th>text</th>\n",
       "      <th>Hash_tag2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>shmee150</td>\n",
       "      <td>CSzoxcyrzj2</td>\n",
       "      <td>1629485286</td>\n",
       "      <td>19080</td>\n",
       "      <td>49</td>\n",
       "      <td>Photo shared by Tim - Shmee on August 20, 2021...</td>\n",
       "      <td>Back at the wheel of an SF90! With @bannedauto...</td>\n",
       "      <td>[['Ferrari'], ['SF90'], ['futureshmeemobile'],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>shmee150</td>\n",
       "      <td>CSr2jQPjy59</td>\n",
       "      <td>1629224075</td>\n",
       "      <td>22143</td>\n",
       "      <td>100</td>\n",
       "      <td>Photo shared by Tim - Shmee on August 17, 2021...</td>\n",
       "      <td>It's a P1 kinda day! Out for a drive in @super...</td>\n",
       "      <td>[['McLaren'], ['P1'], ['McLarenP1'], ['testdri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1    author    shortcode   timestamp  likes  \\\n",
       "0           0             0  shmee150  CSzoxcyrzj2  1629485286  19080   \n",
       "1           1             1  shmee150  CSr2jQPjy59  1629224075  22143   \n",
       "\n",
       "   comments                                            caption  \\\n",
       "0        49  Photo shared by Tim - Shmee on August 20, 2021...   \n",
       "1       100  Photo shared by Tim - Shmee on August 17, 2021...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Back at the wheel of an SF90! With @bannedauto...   \n",
       "1  It's a P1 kinda day! Out for a drive in @super...   \n",
       "\n",
       "                                           Hash_tag2  \n",
       "0  [['Ferrari'], ['SF90'], ['futureshmeemobile'],...  \n",
       "1  [['McLaren'], ['P1'], ['McLarenP1'], ['testdri...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv output from Instagrapy_split_text.ipynb\n",
    "df=pd.read_csv(\"../../resources/ig_datascrape_jc_2021-08-25.csv\", encoding=\"ISO 8859-1\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed51eb88",
   "metadata": {},
   "source": [
    "## Punctuation Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18cc65bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# library that contains punctuation\n",
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced7f895",
   "metadata": {},
   "source": [
    "The following script removes \"@\". Do we need to modify the script to keep it? If so, we will have to use Regex to more finely tune the punctuation removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfa0648c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>author</th>\n",
       "      <th>shortcode</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>caption</th>\n",
       "      <th>text</th>\n",
       "      <th>Hash_tag2</th>\n",
       "      <th>clean_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>shmee150</td>\n",
       "      <td>CSzoxcyrzj2</td>\n",
       "      <td>1629485286</td>\n",
       "      <td>19080</td>\n",
       "      <td>49</td>\n",
       "      <td>Photo shared by Tim - Shmee on August 20, 2021...</td>\n",
       "      <td>Back at the wheel of an SF90! With @bannedauto...</td>\n",
       "      <td>[['Ferrari'], ['SF90'], ['futureshmeemobile'],...</td>\n",
       "      <td>[Back at the wheel of an SF90 With bannedauto ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1    author    shortcode   timestamp  likes  \\\n",
       "0           0             0  shmee150  CSzoxcyrzj2  1629485286  19080   \n",
       "\n",
       "   comments                                            caption  \\\n",
       "0        49  Photo shared by Tim - Shmee on August 20, 2021...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Back at the wheel of an SF90! With @bannedauto...   \n",
       "\n",
       "                                           Hash_tag2  \\\n",
       "0  [['Ferrari'], ['SF90'], ['futureshmeemobile'],...   \n",
       "\n",
       "                                           clean_txt  \n",
       "0  [Back at the wheel of an SF90 With bannedauto ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining the function to remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "#storing the puntuation free text\n",
    "df['clean_txt']= df['text'].apply(lambda x: [remove_punctuation(str(x))])\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de44a3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of rows in DataFrame\n",
    "number_of_rows = len(df)\n",
    "\n",
    "number_of_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a309370d",
   "metadata": {},
   "source": [
    "## Lowercase Text Manipulation\n",
    "PROBLEM. Lower only works on strings. Two options: call lower on each element using a for loop, or turn the list into a string, then call lower on it.\n",
    "<br>\n",
    "Psudeo code example:\n",
    "<br>\n",
    "<p> original_list = ['A','B','C']\n",
    "<p> new_list = []\n",
    "<p> for item in original_list:\n",
    "<p> new_list.append(str.lower(item))\n",
    "<p> print(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd7896d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-d5be8b216e33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'msg_lower'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clean_txt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# df[\"text\"] = df[\"text\"].apply(lambda x: [sent.text for sent in (nlp(str(x)).sents)])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jchan\\anaconda3\\envs\\pythondata\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4043\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4044\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4045\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4047\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-d5be8b216e33>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'msg_lower'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clean_txt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# df[\"text\"] = df[\"text\"].apply(lambda x: [sent.text for sent in (nlp(str(x)).sents)])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "df['msg_lower']= df['clean_txt'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866ae678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Unnamed columns\n",
    "df =df.drop(['Unnamed: 0.1'], axis=1)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# convert epoch time to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'],unit='s')\n",
    "\n",
    "# assign first_text to first row's \"text\" column\n",
    "ig_text = df.loc[0, \"text\"]\n",
    "print(ig_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0b194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b51e08",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a02842",
   "metadata": {},
   "source": [
    "Resources to better understand text preprocessing\n",
    "<br>\n",
    "[Tokenize Text Columns Into Sentences in Pandas](https://towardsdatascience.com/tokenize-text-columns-into-sentences-in-pandas-2c08bc1ca790)\n",
    "<br>\n",
    "Note that v3 of spacy replaces \"nlp.create_pipe\", with \"nlp.add_pipe('sentencizer')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465cbd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# required library and a spacy model\n",
    "\n",
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a661de17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test. Tokenize using spaCy\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "[sent.text for sent in nlp(ig_text).sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6875577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()  # just the language with no model\n",
    "sentencizer = nlp.add_pipe('sentencizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440878c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "[sent.text for sent in nlp(ig_text).sents]\n",
    "\n",
    "# END Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaf1cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize all data, in column \"text\", using lambda function\n",
    "# this was a pain. some elements were ints or floats, causing mixed returns of a dtype \n",
    "# object type. This stopped the script from filtering it out, returning a \"nlp object \n",
    "# of type 'float' has no len()\". the workaround is to turn everything into a string\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: [sent.text for sent in (nlp(str(x)).sents)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82693b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list of sentences to one sentence for each row\n",
    "\n",
    "df = df.explode(\"text\")\n",
    "df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d862086",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"Unnamed: 0\": \"Dialogue ID\"}, inplace=True)\n",
    "df.index.name = \"Sentence ID\"\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96578ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../../resources/processed_ig_text_jc_2021-08-26.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e20922",
   "metadata": {},
   "source": [
    "## To do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d740eb",
   "metadata": {},
   "source": [
    "Need to remove \",\" , \"-\", \"@\", \"#\",  convert conjugations into full words, e.g. isn't."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
