{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c4dad70",
   "metadata": {},
   "source": [
    "# Text Preprocessing in NLP\n",
    "Tokenize Text Columns Into Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de769482",
   "metadata": {},
   "source": [
    "Required libraries\n",
    "<br>\n",
    "[pip install spacy](https://pypi.org/project/spacy/)\n",
    "[conda install jupyter](\n",
    "<br>\n",
    "Input the following into gitbash: \"python -m spacy download en_core_web_sm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eb126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies and setup\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a085e980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv output from Instagrapy_split_text.ipynb\n",
    "df=pd.read_csv(\"../../resources/ig_datascrape_jc_2021-08-25.csv\", encoding=\"ISO 8859-1\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f021fe51",
   "metadata": {},
   "source": [
    "## Data Cleaning Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db347c77",
   "metadata": {},
   "source": [
    "### Punctuation Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4848da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert epoch time to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'],unit='s')\n",
    "\n",
    "# force change, of specified column type, to string.\n",
    "df.text = df.text.astype('string')\n",
    "df.caption = df.caption.astype('string')\n",
    "df.Hash_tag2 = df.Hash_tag2.astype('string')\n",
    "\n",
    "df.dtypes  # verify string change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95237227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library that contains punctuation\n",
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4416058a",
   "metadata": {},
   "source": [
    "The following script removes \"@\". Do we need to modify the script to keep it? If so, we will have to use Regex to more finely tune the punctuation removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f79bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the function to remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "\n",
    "# storing the puntuation free text in a new column\n",
    "df['clean_txt']= df['text'].apply(lambda x: [remove_punctuation(str(x))])\n",
    "df.clean_txt = df.clean_txt.astype('string')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ccb4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of rows in DataFrame\n",
    "number_of_rows = len(df)\n",
    "\n",
    "number_of_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da499da8",
   "metadata": {},
   "source": [
    "### Lowercase Text Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b635f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing all lower case text in a new column, \"txt_lower\". Note this leads to loss of\n",
    "# information that a capital letter may convey, e.g. frustration or excitement.\n",
    "df['txt_lower']= df['clean_txt'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c369cdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb832589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Unnamed columns\n",
    "df =df.drop(['Unnamed: 0.1'], axis=1)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# verify above scripts work. assign first_text to first row's \"txt_lower\" column\n",
    "# all punctuations now removed, and words in lower case\n",
    "ig_text = df.loc[0, \"txt_lower\"]\n",
    "print(ig_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bee1d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify \"Unammed 0.1\" was dropped\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86863463",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbe5dd3",
   "metadata": {},
   "source": [
    "Resources to better understand text preprocessing\n",
    "<br>\n",
    "[Tokenize Text Columns Into Sentences in Pandas](https://towardsdatascience.com/tokenize-text-columns-into-sentences-in-pandas-2c08bc1ca790)\n",
    "<br>\n",
    "Note that v3 of spacy replaces \"nlp.create_pipe\", with \"nlp.add_pipe('sentencizer')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bf5eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# required library and a spacy model un-comment and run if not already installed\n",
    "\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b829ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test. Tokenize using spaCy\n",
    "import spacy\n",
    "\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# [sent.text for sent in nlp(ig_text).sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6a9ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()  # just the language with no model\n",
    "sentencizer = nlp.add_pipe('sentencizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57bcf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "[sent.text for sent in nlp(ig_text).sents]\n",
    "\n",
    "# END Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b5e00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize all data, in column \"text\", using lambda function\n",
    "# this was a pain. some elements were ints or floats, causing mixed returns of a dtype \n",
    "# object type. This stopped the script from filtering it out, returning a \"nlp object \n",
    "# of type 'float' has no len()\". the workaround is to turn everything into a string\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "df[\"txt_lower\"] = df[\"txt_lower\"].apply(lambda x: [sent.text for sent in (nlp(str(x)).sents)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9ff598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list of sentences to one sentence for each row\n",
    "\n",
    "df = df.explode(\"txt_lower\")\n",
    "df.reset_index(drop=True)\n",
    "df.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fe1641",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"Unnamed: 0\": \"Dialogue ID\"}, inplace=True)\n",
    "df.index.name = \"Sentence ID\"\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67857c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../../resources/processed_ig_text_jc_2021-08-26.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085d7302",
   "metadata": {},
   "source": [
    "Need to remove \",\" , \"-\", \"@\", \"#\",  convert conjugations into full words, e.g. isn't."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
