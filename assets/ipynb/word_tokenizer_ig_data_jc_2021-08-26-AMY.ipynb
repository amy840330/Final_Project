{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c4dad70",
   "metadata": {},
   "source": [
    "# Text Preprocessing in NLP\n",
    "Tokenize Text Columns Into Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89f099b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy) (3.7.4.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy) (1.19.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.8 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy) (8.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy) (4.62.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy) (20.9)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy) (3.0.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy) (47.3.1.post20200622)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy) (0.6.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy) (2.4.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from catalogue<2.1.0,>=2.0.4->spacy) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.0)\n",
      "Requirement already satisfied: dataclasses<1.0,>=0.6 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from pathy>=0.3.5->spacy) (0.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n",
      "Requirement already satisfied: contextvars<3,>=2.4 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from thinc<8.1.0,>=8.0.8->spacy) (2.4)\n",
      "Requirement already satisfied: immutables>=0.9 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from contextvars<3,>=2.4->thinc<8.1.0,>=8.0.8->spacy) (0.16)\n",
      "Requirement already satisfied: colorama in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0.0rc2 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from jinja2->spacy) (2.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.1.2; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\17076\\anaconda3\\envs\\pythondata\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6 MB)\n",
      "Requirement already satisfied: spacy<3.2.0,>=3.1.0 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from en-core-web-sm==3.1.0) (3.1.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (47.3.1.post20200622)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.7.4.3)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.8 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (20.9)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.3.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.62.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.19.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from catalogue<2.1.0,>=2.0.4->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.2.0)\n",
      "Requirement already satisfied: dataclasses<1.0,>=0.6 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2021.5.30)\n",
      "Requirement already satisfied: contextvars<3,>=2.4 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from thinc<8.1.0,>=8.0.8->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4)\n",
      "Requirement already satisfied: immutables>=0.9 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from contextvars<3,>=2.4->thinc<8.1.0,>=8.0.8->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.16)\n",
      "Requirement already satisfied: colorama in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.4)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0.0rc2 in c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.0)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-27 15:15:07.457450: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-08-27 15:15:07.457512: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\17076\\anaconda3\\envs\\pythondata\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.1.2; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\17076\\anaconda3\\envs\\PythonData\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# Required libraries\n",
    "\n",
    "# [pip install spacy](https://pypi.org/project/spacy/)\n",
    "\n",
    "# Input the following into gitbash: \"python -m spacy download en_core_web_sm\"\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!conda install -c anaconda nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eb126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies and setup\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a085e980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv output from Instagrapy_split_text.ipynb\n",
    "df=pd.read_csv(\"../../resources/ig_datascrape_jc_2021-08-25.csv\", encoding=\"ISO 8859-1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-trace",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Cleaning Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4848da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert epoch time to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'],unit='s')\n",
    "\n",
    "# force change, of specified column type, to string.\n",
    "df.text = df.text.astype('string')\n",
    "df.caption = df.caption.astype('string')\n",
    "df.Hash_tag2 = df.Hash_tag2.astype('string')\n",
    "\n",
    "df.dtypes  # verify string change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db347c77",
   "metadata": {},
   "source": [
    "### Punctuation Removal\n",
    "** Currently causing issues with sentence segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95237227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library that contains punctuation\n",
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4416058a",
   "metadata": {},
   "source": [
    "The following script removes \"@\". Do we need to modify the script to keep it? If so, we will have to use Regex to more finely tune the punctuation removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f79bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the function to remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "\n",
    "# storing the puntuation free text in a new column\n",
    "df['clean_txt']= df['text'].apply(lambda x: [remove_punctuation(str(x))])\n",
    "df.clean_txt = df.clean_txt.astype('string')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb832589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Unnamed columns\n",
    "df =df.drop(['Unnamed: 0.1'], axis=1)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# verify above scripts work. assign first_text to first row's \"txt_lower\" column\n",
    "# all punctuations now removed, and words in lower case\n",
    "ig_text = df.loc[0, \"clean_txt\"]   ##** Punc_changes. changed from text to \"clean_text\"\n",
    "print(ig_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bee1d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify \"Unammed 0.1\" was dropped\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86863463",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbe5dd3",
   "metadata": {},
   "source": [
    "Resources to better understand text preprocessing\n",
    "<br>\n",
    "[Tokenize Text Columns Into Sentences in Pandas](https://towardsdatascience.com/tokenize-text-columns-into-sentences-in-pandas-2c08bc1ca790)\n",
    "<br>\n",
    "Note that v3 of spacy replaces \"nlp.create_pipe\", with \"nlp.add_pipe('sentencizer')\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b69ebfc",
   "metadata": {},
   "source": [
    "Sentencizer is a pipeline component for rules-based sentence segmentation\n",
    "[spacy boundry detection](https://spacy.io/api/sentencizer). Customization option includes creation of custom list of punctuation characters that mark sentence ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b829ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize using spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "[sent.text for sent in nlp(ig_text).sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6a9ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()  # just the language with no model\n",
    "sentencizer = nlp.add_pipe('sentencizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57bcf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "[sent.text for sent in nlp(ig_text).sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b5e00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize all data, in column \"text\", using lambda function\n",
    "# this was a pain. some elements were ints or floats, causing mixed returns of a dtype \n",
    "# object type. This stopped the script from filtering it out, returning a \"nlp object \n",
    "# of type 'float' has no len()\". the workaround is to turn everything into a string\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "df[\"token_txt\"] = df[\"clean_txt\"].apply(lambda x: [sent.text for sent in (nlp(str(x)).sents)])\n",
    "\n",
    "##** Punc_changes. changed from text to \"clean_text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9ff598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list of sentences to one sentence for each row\n",
    "\n",
    "df = df.explode(\"token_txt\")\n",
    "df.reset_index(drop=True)\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-knife",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tokenized\"] = df[\"clean_txt\"].apply(lambda x: x.split())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-friday",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-interstate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem.porter import *\n",
    "# stemmer = PorterStemmer()\n",
    "\n",
    "# df[\"tokenized\"] = df[\"tokenized\"].apply(lambda x: [stemmer.stem(i) for i in x]) # stemming\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "df[\"tokenized\"] = df[\"tokenized\"].apply(lambda x: [wordnet_lemmatizer.lemmatize(i) for i in x]) # stemming\n",
    "\n",
    "\n",
    "df[\"tokenized\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df= df.explode(\"tokenized\")\n",
    "# df.reset_index(drop=True)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-leonard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #remove the square bracket\n",
    "# df['tokenized']= df['tokenized'].str.strip('[]').astype(str)\n",
    "# df.head()\n",
    "# df2=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-pleasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbdf=df2.groupby('author').agg({'tokenized': lambda x: ' '.join(x)})\n",
    "# gbdf['tokenized'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbdf[\"tokenized\"] = gbdf[\"tokenized\"].apply(lambda x: x.split())\n",
    "# gbdf.head()\n",
    "\n",
    "# # from nltk.corpus import stopwords\n",
    "\n",
    "# # nltk.download(\"stopwords\")\n",
    "\n",
    "# # stopwords_ = set(stopwords.words(\"english\"))\n",
    "\n",
    "# # clean_tokens = [t for t in gbdf[\"tokenized\"] if not t in stopwords_]\n",
    "# # # clean_text = \" \".join(clean_tokens)\n",
    "# # # print_text(clean_text)\n",
    "# # clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553e9e86",
   "metadata": {},
   "source": [
    "### Lowercase Text Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b635f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing all lower case text in a new column, \"txt_lower\". Note this leads to loss of\n",
    "# information that a capital letter may convey, e.g. frustration or excitement.\n",
    "# df['txt_lower']= df['clean_txt'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de14c080",
   "metadata": {},
   "source": [
    "### Column Name Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fe1641",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"Unnamed: 0\": \"Dialogue ID\"}, inplace=True)\n",
    "df.index.name = \"Sentence ID\"\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67857c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../../resources/processed_ig_text_jc_2021-08-26.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085d7302",
   "metadata": {},
   "source": [
    "Need to remove \",\" , \"-\", \"@\", \"#\",  convert conjugations into full words, e.g. isn't."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-divide",
   "metadata": {},
   "source": [
    "### Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_posts = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-beverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_posts.values[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-exception",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-waterproof",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-capture",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia.polarity_scores('Dartanion is the greatest in the world!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-newcastle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['neg'] = None\n",
    "df['neu'] = None\n",
    "df['pos'] = None\n",
    "df['compound'] = None\n",
    "\n",
    "for k, v in df.iterrows():\n",
    "    post = v['text']\n",
    "    \n",
    "    try:\n",
    "        pol_scores = sia.polarity_scores(post)\n",
    "    except:\n",
    "        print(f'Error with record {k}. Moving on...')\n",
    "    \n",
    "    df.loc[k,'neg'] = pol_scores['neg']\n",
    "    df.loc[k,'neu'] = pol_scores['neu']\n",
    "    df.loc[k,'pos'] = pol_scores['pos']\n",
    "    df.loc[k,'compound'] = pol_scores['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-learning",
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence ID</th>\n",
       "      <th>Dialogue ID</th>\n",
       "      <th>author</th>\n",
       "      <th>shortcode</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>caption</th>\n",
       "      <th>text</th>\n",
       "      <th>Hash_tag2</th>\n",
       "      <th>clean_txt</th>\n",
       "      <th>token_txt</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>shmee150</td>\n",
       "      <td>CSzoxcyrzj2</td>\n",
       "      <td>2021-08-20 18:48:06</td>\n",
       "      <td>19080</td>\n",
       "      <td>49</td>\n",
       "      <td>Photo shared by Tim - Shmee on August 20, 2021...</td>\n",
       "      <td>Back at the wheel of an SF90! With @bannedauto...</td>\n",
       "      <td>[['Ferrari'], ['SF90'], ['futureshmeemobile'],...</td>\n",
       "      <td>['Back at the wheel of an SF90 With bannedauto...</td>\n",
       "      <td>['Back at the wheel of an SF90 With bannedauto...</td>\n",
       "      <td>[['Back, at, the, wheel, of, an, SF90, With, b...</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.9379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence ID  Dialogue ID    author    shortcode           timestamp  likes  \\\n",
       "0            0            0  shmee150  CSzoxcyrzj2 2021-08-20 18:48:06  19080   \n",
       "\n",
       "   comments                                            caption  \\\n",
       "0        49  Photo shared by Tim - Shmee on August 20, 2021...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Back at the wheel of an SF90! With @bannedauto...   \n",
       "\n",
       "                                           Hash_tag2  \\\n",
       "0  [['Ferrari'], ['SF90'], ['futureshmeemobile'],...   \n",
       "\n",
       "                                           clean_txt  \\\n",
       "0  ['Back at the wheel of an SF90 With bannedauto...   \n",
       "\n",
       "                                           token_txt  \\\n",
       "0  ['Back at the wheel of an SF90 With bannedauto...   \n",
       "\n",
       "                                           tokenized    neg    neu    pos  \\\n",
       "0  [['Back, at, the, wheel, of, an, SF90, With, b...  0.027  0.801  0.172   \n",
       "\n",
       "  compound  \n",
       "0   0.9379  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "outputs": [],
>>>>>>> 9e81b0190e5bdc89f91ed3327dc622fa1f670ed8
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9889ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence ID             int64\n",
       "Dialogue ID             int64\n",
       "author                 object\n",
       "shortcode              object\n",
       "timestamp      datetime64[ns]\n",
       "likes                   int64\n",
       "comments                int64\n",
       "caption                string\n",
       "text                   string\n",
       "Hash_tag2              object\n",
       "clean_txt              string\n",
       "token_txt              object\n",
       "tokenized              object\n",
       "neg                    object\n",
       "neu                    object\n",
       "pos                    object\n",
       "compound               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.Hash_tag2 = df.Hash_tag2.astype('object')\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "95f27db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ig_perf_summary = new_df.groupby('Author')['Likes', 'Comments', 'Neg', 'neu', 'Pos', 'Compound'].sum().reset_index()\n",
    "ig_hashtag_summary = df.groupby('author')['Hash_tag2'].sum()\n",
    "\n",
    "ig_hashtag_summary.head(25)\n",
    "\n",
    "ig_hashtag_summary.to_csv(\"../../resources/ig_hashtag_summary_jc_2021-08-26.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 46,
=======
   "execution_count": null,
>>>>>>> 9e81b0190e5bdc89f91ed3327dc622fa1f670ed8
   "id": "pleased-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../../resources/sentiment_jc_2021-08-26.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
